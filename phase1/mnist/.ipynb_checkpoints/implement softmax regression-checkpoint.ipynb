{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A set of \"m\" samples, each a vector of \"n\" input features: \n",
    "$$X_i = {x_{1i},x_{2i},x_{3i},...,x_{ni}}$$\n",
    "* A set of corresponding \"m\" output vectors of length k, where only one of the k values is 1.0, and the other are 0.0 (this is the one-hot encoding):\n",
    "$$y_i = {y_{0i},y_{1i},y_{2i},...,y_{(k-1)i},}$$\n",
    "\n",
    "* The classifier has \"k\" outputs, each of the form:\n",
    "$$p_k = {{e^{X\\theta_k}}\\over{\\sum_{i=0}^{i=k-1}e^{X\\theta_k}}}$$\n",
    "where $p_k$ is the probability that the class=k for that specific set of features. \n",
    "\n",
    "define the cost function $J(\\theta)$:\n",
    "$$J(\\theta) = -{1\\over{m}}\\sum_{i=1}^m \\sum_{j=0}^{k-1}1[y^{(i)}=j] ~log{e^{\\theta_j X}\\over{\\sum_{\\ell=0}^k}e^{\\theta_\\ell X}}$$\n",
    "Note that the term $1[y^{(i)}=j]$ equals 1 when the true output $y^{i}=j$ for the specific output class j.\n",
    "\n",
    "the gradient of the cost function with respect to $\\theta$ for a single output $j$ is:\n",
    " $${\\delta J\\over{\\partial \\theta_j}} =X \\left( 1-{e^{\\theta_j X}\\over{\\sum_{\\ell=0}^k e^{\\theta_\\ell X} }} \\right) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement the softmax function\n",
    "\n",
    "$$p_k = {{e^{X\\theta_k}}\\over{\\sum_{i=0}^{i=k-1}e^{X\\theta_k}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax function:\n",
    "def softmax(Theta, Xp):\n",
    "    # data has m input rows, n features, k outputs\n",
    "    # Theta is (n+1) by k matrix\n",
    "    z = np.dot(Xp, Theta)\n",
    "    z -= np.max(z) # get the max and subtract to deal with large number\n",
    "    res = np.exp(z)/np.sum(np.exp(z), axis=1)[:,np.newaxis]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement cost function for softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "def cost_softmax(Theta, Xp, yp_oneHot, Lambda):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
